{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and Preview Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from 'creditcard_2023.csv' into a DataFrame and set 'id' as the index column\n",
    "df = pd.read_csv('creditcard_2023.csv', index_col='id')\n",
    "\n",
    "# Print the shape of the DataFrame to show the number of rows and columns\n",
    "print(df.shape)\n",
    "\n",
    "# Display the first five rows of the DataFrame to provide a quick overview of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize and Apply Standard Scaler to Selected Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# List of columns to be scaled\n",
    "# These are the feature columns that will be standardized\n",
    "columns_to_scale = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
    "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
    "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\n",
    "\n",
    "# Fit the scaler on the columns and transform them\n",
    "# This will standardize the feature columns in-place\n",
    "df[columns_to_scale] = scaler.fit_transform(df[columns_to_scale])\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify the scaling\n",
    "# This allows you to check that the scaling was applied correctly\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display Class Distribution for Original and Subsampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the class distribution in the original DataFrame\n",
    "print(df['Class'].value_counts())\n",
    "\n",
    "# Create a new DataFrame 'df1' by slicing rows from index 69000 to 500000\n",
    "df1 = df.iloc[69000:500000,:]\n",
    "\n",
    "# Print the class distribution in the new DataFrame 'df1'\n",
    "print(df1['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Sub-DataFrame and Reset Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame 'df2' by slicing rows 212100 to 220000 from 'df1'\n",
    "df2 = df1.iloc[212100:220000,:]\n",
    "\n",
    "# Reset the index of 'df2' and drop the old index\n",
    "df2 = df2.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle DataFrame and Display Basic Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the DataFrame rows randomly\n",
    "df2 = df2.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Display the first 500 rows of the shuffled DataFrame for preview\n",
    "df2.head(500)\n",
    "\n",
    "# Print the shape of the DataFrame to show the number of rows and columns\n",
    "df2.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-NN Model Training and Hyperparameter Tuning with Multiple Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and target variable from the DataFrame 'df2'\n",
    "X = df2.iloc[:7000, 0:29]  # Features (first 29 columns)\n",
    "y = df2.iloc[:7000, 29]    # Target variable (30th column)\n",
    "\n",
    "# Define lists for different metrics, weights, and test sizes to be used in k-NN\n",
    "metrics_list = ['euclidean', 'manhattan', 'minkowski', 'chebyshev', 'hamming', 'canberra', 'braycurtis', 'jaccard', 'dice', 'kulsinski', 'rogerstanimoto', 'russellrao', 'sokalmichener', 'sokalsneath', 'yule', 'cosine', 'correlation']\n",
    "weights_list = ['uniform', 'distance']\n",
    "ts_range = [.1,.2,.3]\n",
    "\n",
    "# Initialize empty lists to store accuracy scores and parameter combinations\n",
    "accuracyScoreResults = []\n",
    "params = []\n",
    "\n",
    "# Nested loops to iterate through different combinations of hyperparameters\n",
    "for num in range(2,3):  # Number of neighbors\n",
    "    for ts in ts_range:  # Test size\n",
    "        for i in metrics_list:  # Distance metric\n",
    "            for j in weights_list:  # Weight type\n",
    "                # Split the data into training and test sets\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ts, random_state=7)\n",
    "                \n",
    "                # Initialize k-NN classifier with current hyperparameters\n",
    "                knn = KNeighborsClassifier(n_neighbors=num, metric=i, weights=j)\n",
    "                \n",
    "                # Train the k-NN model\n",
    "                knn.fit(X_train, y_train)\n",
    "                \n",
    "                # Make predictions on the test set\n",
    "                y_pred = knn.predict(X_test)\n",
    "                \n",
    "                # Evaluate the model and store results\n",
    "                if accuracy_score(y_test, y_pred) == 1:\n",
    "                    print(f\"Accuracy of KNN = {num}, Metric = {i}, Weight = {j}, TS = {ts}:\", accuracy_score(y_test, y_pred))\n",
    "                    accuracyScoreResults.append(accuracy_score(y_test, y_pred))\n",
    "                    params.append([num, i, j, ts])\n",
    "                else:\n",
    "                    accuracyScoreResults.append(accuracy_score(y_test, y_pred))\n",
    "                    params.append([num, i, j, ts])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find and Display Best Model Parameters and Maximum Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum accuracy score from the list of results\n",
    "max_value = max(accuracyScoreResults)\n",
    "\n",
    "# Find the index of the maximum accuracy score\n",
    "max_index = accuracyScoreResults.index(max_value)\n",
    "\n",
    "# Retrieve the number of neighbors corresponding to the maximum accuracy\n",
    "neighbors = params[max_index][0]\n",
    "\n",
    "# Retrieve the distance metric corresponding to the maximum accuracy\n",
    "metric = params[max_index][1]\n",
    "\n",
    "# Retrieve the weight type corresponding to the maximum accuracy\n",
    "weights = params[max_index][2]\n",
    "\n",
    "# Print the parameters that yielded the maximum accuracy\n",
    "print(params[max_index])\n",
    "\n",
    "# Print the maximum accuracy value\n",
    "print(max_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and Evaluate k-NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X and y are already defined\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=7)\n",
    "\n",
    "# Initialize k-NN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=neighbors, metric=metric, weights=weights)\n",
    "\n",
    "# Train the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate and Display Model Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using various metrics\n",
    "\n",
    "# Calculate Accuracy: Proportion of correctly predicted observations to the total observations\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Precision: Proportion of correctly predicted positive observations to the total predicted positives\n",
    "precision = precision_score(y_test, y_pred, average='weighted')  # Change 'weighted' as per your needs\n",
    "\n",
    "# Calculate Recall: Proportion of correctly predicted positive observations to the all observations in actual class\n",
    "recall = recall_score(y_test, y_pred, average='weighted')  # Change 'weighted' as per your needs\n",
    "\n",
    "# Calculate F1 Score: Weighted average of Precision and Recall\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')  # Change 'weighted' as per your needs\n",
    "\n",
    "# Generate Confusion Matrix: Shows the ways in which your classification model is confused when it makes predictions\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Confusion Matrix: \\n{conf_matrix}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Model on New Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the feature columns for the new test set\n",
    "new_X_test = df2.iloc[7000:,:29]\n",
    "\n",
    "# Select the target column for the new test set\n",
    "new_y_test = df2.iloc[7000:,29]\n",
    "\n",
    "# Make predictions using the trained k-NN model\n",
    "new_y_pred = knn.predict(new_X_test)\n",
    "\n",
    "# Evaluate the model's performance on the new test set\n",
    "print(accuracy_score(new_y_test, new_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Model Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using various metrics\n",
    "\n",
    "# Calculate the accuracy of the model on the test set\n",
    "accuracy = accuracy_score(new_y_test, new_y_pred)\n",
    "\n",
    "# Calculate the weighted precision of the model\n",
    "# Change 'weighted' to other options like 'micro', 'macro', etc., as per your needs\n",
    "precision = precision_score(new_y_test, new_y_pred, average='weighted')\n",
    "\n",
    "# Calculate the weighted recall of the model\n",
    "# Change 'weighted' to other options like 'micro', 'macro', etc., as per your needs\n",
    "recall = recall_score(new_y_test, new_y_pred, average='weighted')\n",
    "\n",
    "# Calculate the weighted F1 score of the model\n",
    "# Change 'weighted' to other options like 'micro', 'macro', etc., as per your needs\n",
    "f1 = f1_score(new_y_test, new_y_pred, average='weighted')\n",
    "\n",
    "# Generate the confusion matrix for the model predictions\n",
    "conf_matrix = confusion_matrix(new_y_test, new_y_pred)\n",
    "\n",
    "# Print out the calculated metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Confusion Matrix: \\n{conf_matrix}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Sampling and Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize counter for correct predictions\n",
    "countCorrect = 0\n",
    "\n",
    "# Number of random samples to test\n",
    "rng = 10000\n",
    "\n",
    "# Loop through rng times to make random predictions\n",
    "for i in range(rng):\n",
    "    # Generate two random integers, one from each class range\n",
    "    rand1 = random.randint(1, 68000)  # Class 0 range\n",
    "    rand2 = random.randint(500001, 560000)  # Class 1 range\n",
    "    \n",
    "    # Create a list of the two random integers\n",
    "    randRand = [rand1, rand2]\n",
    "    \n",
    "    # Randomly select one integer from the list\n",
    "    randSelect = randRand[random.randint(0, 1)]\n",
    "    \n",
    "    # Fetch the row corresponding to the random integer from the DataFrame\n",
    "    sampleRow = df.iloc[randSelect, :30]\n",
    "    \n",
    "    # Separate features and target label\n",
    "    sampleRow_X = sampleRow.drop('Class')\n",
    "    sampleRow_y = sampleRow['Class']\n",
    "    \n",
    "    # Reshape the row to be a 2D array for prediction\n",
    "    sampleRowReshaped = sampleRow_X.values.reshape(1, -1)\n",
    "    \n",
    "    # Use the trained model to make a prediction\n",
    "    sampleRowPrediction = knn.predict(sampleRowReshaped)\n",
    "    \n",
    "    # Check if the prediction is correct and update the counter if so\n",
    "    if sampleRowPrediction[0] == sampleRow_y:\n",
    "        countCorrect += 1\n",
    "\n",
    "# Calculate and print the percentage of correct predictions\n",
    "print(str(f\"{countCorrect / rng * 100}%\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform k-Fold Cross-Validation with k-NN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize k-NN classifier with specific hyperparameters\n",
    "knn = KNeighborsClassifier(n_neighbors=2, metric='braycurtis', weights='distance')\n",
    "\n",
    "# Number of folds for k-fold cross-validation\n",
    "n_folds = 500\n",
    "\n",
    "# Initialize KFold object with the number of splits, shuffle option, and random seed\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=7)\n",
    "\n",
    "# Initialize an empty list to store the accuracy for each fold\n",
    "accuracy_list = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "# kf.split() will generate indices to split data into training and test sets\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # Extract training and test sets based on indices for this fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Train the k-NN classifier on the current training set\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Use the trained k-NN classifier to make predictions on the test set\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    # Calculate the accuracy of the model for this fold\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Append the accuracy to the list\n",
    "    accuracy_list.append(accuracy)\n",
    "    \n",
    "    # Print the accuracy for this fold\n",
    "    print(f\"Fold accuracy: {accuracy}\")\n",
    "\n",
    "# Calculate and print the mean accuracy across all folds\n",
    "mean_accuracy = np.mean(accuracy_list)\n",
    "print(f\"Mean accuracy over {n_folds} folds: {mean_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define and Test Edge Cases with Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an edge case near the decision boundary\n",
    "edge_case_1 = pd.Series({\n",
    "    'V1': 0.1, 'V2': -0.1, 'V3': 0.2, 'V4': -0.2, 'V5': 0.1, 'V6': -0.1, 'V7': 0.2, 'V8': -0.2, \n",
    "    'V9': 0.1, 'V10': -0.1, 'V11': 0.2, 'V12': -0.2, 'V13': 0.1, 'V14': -0.1, 'V15': 0.2, 'V16': -0.2, \n",
    "    'V17': 0.1, 'V18': -0.1, 'V19': 0.2, 'V20': -0.2, 'V21': 0.1, 'V22': -0.1, 'V23': 0.2, 'V24': -0.2, \n",
    "    'V25': 0.1, 'V26': -0.1, 'V27': 0.2, 'V28': -0.2, 'Amount': 0.05, 'Class': 1  # Actual class label\n",
    "})\n",
    "\n",
    "# Define an outlier edge case\n",
    "edge_case_2 = pd.Series({\n",
    "    'V1': 3, 'V2': -3, 'V3': 3, 'V4': -3, 'V5': 3, 'V6': -3, 'V7': 3, 'V8': -3, \n",
    "    'V9': 3, 'V10': -3, 'V11': 3, 'V12': -3, 'V13': 3, 'V14': -3, 'V15': 3, 'V16': -3, \n",
    "    'V17': 3, 'V18': -3, 'V19': 3, 'V20': -3, 'V21': 3, 'V22': -3, 'V23': 3, 'V24': -3, \n",
    "    'V25': 3, 'V26': -3, 'V27': 3, 'V28': -3, 'Amount': 3, 'Class': 0  # Actual class label\n",
    "})\n",
    "\n",
    "# Reshape the rows to be 2D arrays for prediction\n",
    "edge_case_reshaped_1 = edge_case_1.drop('Class').values.reshape(1, -1)\n",
    "edge_case_reshaped_2 = edge_case_2.drop('Class').values.reshape(1, -1)\n",
    "\n",
    "# Use the trained k-NN model to make predictions for the edge cases\n",
    "edge_case_prediction_1 = knn.predict(edge_case_reshaped_1)\n",
    "edge_case_prediction_2 = knn.predict(edge_case_reshaped_2)\n",
    "\n",
    "# Print the predicted class labels for the edge cases\n",
    "print(f\"The predicted class label for edge_case_1 is: {edge_case_prediction_1[0]}\")\n",
    "print(f\"The predicted class label for edge_case_2 is: {edge_case_prediction_2[0]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
